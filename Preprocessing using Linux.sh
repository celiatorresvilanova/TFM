
###########################################################################################################################################################
                                                                   #LINUX PREPROCESSING                                                                                                                                
###########################################################################################################################################################


# Set the working directory
cd /PROJECTES/MALARIA_IMMUNO/22.SAINT/Transcriptomics/Data

# The merging of three reads per sample was performed using R 4.3.0 (https://github.com/celiatorresvilanova/TFM/blob/main/Preprocessing_R.r). Subsequently, 
# FastQC reports were generated for the merged samples

mkdir merged/Report_merged
fastqc -o merged/Reports_merged merged/*.fastq.gz

######################################################################### TRIMMING #########################################################################

# The samples were analyzed using Illumina NextSeq2000, with the following parameters: single-end reads, stranded, and 50 base pairs in length. To remove
# low-quality reads, sickle was performed, applying the following criteria: quality score (q 20), read length (l 50), single-end reads (se), and sanger
# quality encoding (t sanger). The adoption of sanger quality encoding by Illumina since 2012 requires the specification of -t sanger during the analysis.

for file in merged/*.fastq.gz
     # The output filename was generated by replacing the directory path with merged_quality and removing the .gz extension
     output_file="merged_quality/$(basename ${file} .fastq.gz).fastq"

     # The input file was decompressed and sickle was performed
     gunzip -c "$file" | sickle se -f /dev/stdin -t sanger -o "$output_file" -q 20 -l 50
done

# The final outputs were compressed
cd merged_quality
gzip *.fastq

# FastQC reports were generated for the merged samples after trimming
fastqc -o Reports_merged_quality merged_quality/*.fastq.gz

# A high ratio of duplicates was observed in both the merged files and the merged files after trimming. Duplicate management will be handled post-alignment.

####################################################################### STAR ALIGNMENT #######################################################################

# The files for v43 of the human genome fasta and annotation were downloaded from GENCODE, and then the files were decompressed
gunzip gencode.v43.primary_assembly.basic.annotation.gtf.gz
gunzip GRCh38.primary_assembly-genome.fa GRCh38.fa.gz

# The annotation and genome filenames were changed
mv gencode.v43.primary_assembly.basic.annotation.gtf GRCh38.gtf
mv GRCh38.primary_assembly-genome.fa GRCh38.fa

# Change the sample filenames to make them shorter
cd merged_quality

for file in *.fastq.gz; do
    new_name=$(echo "$file" | sed -E 's/^([^_]+_[^_]+)_.*(\.fastq\.gz)$/\1\2/')
    mv "$file" "$new_name"
done

# A genome index was build taking into accoung the genome and annotation files
mkdir Alignments

STAR --runThreadN 30 \
     --runMode genomeGenerate \
     --genomeDir merged_quality/Alignments/genomeIndex \
     --genomeFastaFiles GRCh38.fa \
     --sjdbGTFfile GRCh38.gtf

# The STAR alignment was conducted with the following parameters:
     # The ReadFilesIn argument separated filenames with commas, as single-end reads are recognized in this manner by the STAR algorithm 
     # The OutSAMunmapped Within argument directed unmapped reads to be written to a separate section in the output file
     # The OutSAMattributes argument specified the attributes to be included in the alignment output: number of hits (NH), alignment hit index (HI), alignment score (AS), number of mismatches (NM) and mismatching positions and lengths (MD)
     # The OutSAMattrRGline argument allowed for specifying sample information for the alignment
     # The ReadFilesCommand argument decompressed the input files
     # The OutSAMtype argument determined the output format and sorting order for the alignment output

STAR --runThreadN 30 \
     --genomeDir Alignments/genomeIndex \
     --readFilesIn S10_1.fastq.gz,S12_2.fastq.gz,S14_2.fastq.gz,S17_1.fastq.gz,S19_3.fastq.gz,S22_1.fastq.gz,S24_1.fastq.gz,S3_3.fastq.gz,S6_2.fastq.gz,S10_2.fastq.gz,S12_3.fastq.gz,S14_3.fastq.gz,S17_2.fastq.gz,S20_1.fastq.gz,S22_2.fastq.gz,S24_2.fastq.gz,S4_1.fastq.gz,S6_3.fastq.gz,S10_3.fastq.gz,S1_2.fastq.gz,S15_1.fastq.gz,S17_3.fastq.gz,S20_2.fastq.gz,S22_3.fastq.gz,S24_3.fastq.gz,S4_2.fastq.gz,S7_1.fastq.gz,S11_1.fastq.gz,S13_1.fastq.gz,S15_2.fastq.gz,S18_1.fastq.gz,S20_3.fastq.gz,S2_2.fastq.gz,S25_1.fastq.gz,S4_3.fastq.gz,S7_2.fastq.gz,S11_2.fastq.gz,S13_2.fastq.gz,S15_3.fastq.gz,S18_2.fastq.gz,S21_1.fastq.gz,S23_1.fastq.gz,S25_2.fastq.gz,S5_1.fastq.gz,S7_3.fastq.gz,S11_3.fastq.gz,S13_3.fastq.gz,S16_1.fastq.gz,S18_3.fastq.gz,S21_2.fastq.gz,S23_2.fastq.gz,S25_3.fastq.gz,S5_2.fastq.gz,S9_1.fastq.gz,S1_1.fastq.gz,S1_3.fastq.gz,S16_2.fastq.gz,S19_1.fastq.gz,S21_3.fastq.gz,S23_3.fastq.gz,S3_1.fastq.gz,S5_3.fastq.gz,S9_2.fastq.gz,S12_1.fastq.gz,S14_1.fastq.gz,S16_3.fastq.gz,S19_2.fastq.gz,S2_1.fastq.gz,S2_3.fastq.gz,S3_2.fastq.gz,S6_1.fastq.gz,S9_3.fastq.gz \
     --outSAMunmapped Within \
     --outSAMattributes NH HI AS NM MD \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix Alignments/

# The output file were checked 
samtools view -h Alignments/Aligned.sortedByCoord.out.bam | more

# The mapping statistics of STAR alignment were checked
cat Alignments/Aligned.sortedByCoord.out.Log.final.out


                                        #                                Started job on |       May 29 13:20:54
                                        #                            Started mapping on |       May 29 13:25:34
                                        #                                   Finished on |       May 29 21:12:02
                                        #      Mapping speed, Million of reads per hour |       433.58

                                        #                         Number of input reads |       3370842019
                                        #                     Average input read length |       50
                                        #                                   UNIQUE READS:
                                        #                  Uniquely mapped reads number |       2927016651
                                        #                       Uniquely mapped reads % |       86.83%
                                        #                         Average mapped length |       49.89
                                        #                      Number of splices: Total |       432051703
                                        #           Number of splices: Annotated (sjdb) |       425276145
                                        #                      Number of splices: GT/AG |       428172907
                                        #                      Number of splices: GC/AG |       2865854
                                        #                      Number of splices: AT/AC |       374986
                                        #              Number of splices: Non-canonical |       637956
                                        #                     Mismatch rate per base, % |       0.24%
                                        #                        Deletion rate per base |       0.01%
                                        #                       Deletion average length |       1.35
                                        #                       Insertion rate per base |       0.00%
                                        #                      Insertion average length |       1.25
                                        #                            MULTI-MAPPING READS:
                                        #       Number of reads mapped to multiple loci |       387143226
                                        #            % of reads mapped to multiple loci |       11.49%
                                        #       Number of reads mapped to too many loci |       16489618
                                        #            % of reads mapped to too many loci |       0.49%
                                        #                                 UNMAPPED READS:
                                        # Number of reads unmapped: too many mismatches |       0
                                        #      % of reads unmapped: too many mismatches |       0.00%
                                        #           Number of reads unmapped: too short |       25110939
                                        #                % of reads unmapped: too short |       0.74%
                                        #               Number of reads unmapped: other |       15081585
                                        #                    % of reads unmapped: other |       0.45%
                                        #                                 CHIMERIC READS:
                                        #                      Number of chimeric reads |       0
                                        #                           % of chimeric reads |       0.00%


# Firstly, I performed an alignment with all the samples together to get a general overview of the alignment statistics: total number
# of reads, percentage of reads uniquely mapped, multiply mapped, and unmapped. Afterwards, I will generate a loop to align the samples
# individually, obtaining one output for each sample. The arguments --outSAMunmapped and --outSAMattributes have been left as default, 
# resulting in the removal of unmapped reads and the export of standard attributes (NH, HI, AS, nM).

sample_files=("S10_1.fastq.gz" "S12_2.fastq.gz" "S14_2.fastq.gz" "S17_1.fastq.gz" "S19_3.fastq.gz" "S22_1.fastq.gz" "S24_1.fastq.gz" "S3_3.fastq.gz" "S6_2.fastq.gz" "S10_2.fastq.gz" "S12_3.fastq.gz" "S14_3.fastq.gz" "S17_2.fastq.gz" "S20_1.fastq.gz" "S22_2.fastq.gz" "S24_2.fastq.gz" "S4_1.fastq.gz" "S6_3.fastq.gz" "S10_3.fastq.gz" "S1_2.fastq.gz" "S15_1.fastq.gz" "S17_3.fastq.gz" "S20_2.fastq.gz" "S22_3.fastq.gz" "S24_3.fastq.gz" "S4_2.fastq.gz" "S7_1.fastq.gz" "S11_1.fastq.gz" "S13_1.fastq.gz" "S15_2.fastq.gz" "S18_1.fastq.gz" "S20_3.fastq.gz" "S2_2.fastq.gz" "S25_1.fastq.gz" "S4_3.fastq.gz" "S7_2.fastq.gz" "S11_2.fastq.gz" "S13_2.fastq.gz" "S15_3.fastq.gz" "S18_2.fastq.gz" "S21_1.fastq.gz" "S23_1.fastq.gz" "S25_2.fastq.gz" "S5_1.fastq.gz" "S7_3.fastq.gz" "S11_3.fastq.gz" "S13_3.fastq.gz" "S16_1.fastq.gz" "S18_3.fastq.gz" "S21_2.fastq.gz" "S23_2.fastq.gz" "S25_3.fastq.gz" "S5_2.fastq.gz" "S9_1.fastq.gz" "S1_1.fastq.gz" "S1_3.fastq.gz" "S16_2.fastq.gz" "S19_1.fastq.gz" "S21_3.fastq.gz" "S23_3.fastq.gz" "S3_1.fastq.gz" "S5_3.fastq.gz" "S9_2.fastq.gz" "S12_1.fastq.gz" "S14_1.fastq.gz" "S16_3.fastq.gz" "S19_2.fastq.gz" "S2_1.fastq.gz" "S2_3.fastq.gz" "S3_2.fastq.gz" "S6_1.fastq.gz" "S9_3.fastq.gz")

for file in "${sample_files[@]}"
do
output_prefix="Alignments/Samples/${file%.fastq.gz}"

STAR --runThreadN 32 \
     --genomeDir Alignments/genomeIndex \
     --readFilesIn "$file" \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix "$output_prefix"
done

######################################################################### DUPLICATIONS #########################################################################

# In RNA-Seq, distinguishing between artificial reads and normal read duplication caused by over-sequencing highly expressed genes is challenging. This is because
# duplicate reads are commonly observed in RNA-Seq, and it is not exclusively attributed to technical errors. Highly expressed genes often surpass the threshold of 
# one read per base pair of the exon model, resulting in unavoidable read duplication. To handle this situation, I will mark the duplicates using Sambamba and then 
# perform dupRadar in R 4.3.0 (https://github.com/celiatorresvilanova/TFM/blob/main/Preprocessing_R.r). DupRadar is a tool that allows visualizing the relationship
# between the percentage of duplications and gene expression. 

sambamba markdup -t 32 -p --tmpdir Duplicates Alignments/Aligned.sortedByCoord.out.bam  Duplicates/Aligned.sortedByCoord.out.mark.bam

mkdir Duplicates/Samples

# Set the path to the directory containing the BAM files
directory="Alignments/Samples/"

# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Extract the filename without the extension
  filename=$(basename "$file" .out.bam)

  # Execute the sambamba markdup command for each file
  sambamba markdup -t 32 -p --tmpdir Duplicates "$file" "Duplicates/Samples/${filename}.mark.bam"
done

# By using dupRadar, elevated duplication percentages were obtained, even in lowly expressed genes. Therefore, the decision was made to perform the analysis with two
# datasets: the original data and the data with duplicates removed. The duplicates were removed using Sambamba, specifying the argument -r (remove duplicates).

sambamba markdup -t 32 -r -p --tmpdir Duplicates Alignments/Aligned.sortedByCoord.out.bam  Duplicates/Aligned.sortedByCoord.out.dup.bam

# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Extract the filename without the extension
  filename=$(basename "$file" .out.bam)

  # Execute the sambamba markdup command for each file
  sambamba markdup -t 32 -r -p --tmpdir Duplicates "$file" "Duplicates/Samples/${filename}.dup.bam"
done

# The decision has been made to eliminate duplicates from the previously generated single BAM file, resulting in a reduction of the
# total read count from 3.4 billion to 1 billion. This allows for a general assessment of the number of duplicate reads and, 
# subsequently, the remaining read count after duplicate removal

######################################################################### QUANTIFICATION #########################################################################

# Better quantification with an index of the BAM file is achieved by Htseq. It needs to be performed only on the output of STAR, as the index file has already been
# generated by Sambamba)

# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Execute the samtools index command for each output file of STAR
  samtools index "$file"
done

# The htseq-count quantification was conducted with the following parameters:
     # The -r argument specifies the alignment mode. In this case, was set to "pos", because the reads were aligned in a strand-speciffic manner
     # The -s argument specifies wheter the library is strans-specific or not. In this case is strand-specific (yes)
     # The -i argument specifies the feature type used for counting. In this case, it was set to gene_id, because the counting was performed at the gene level
     # The -t atgument specifies the feature type attribute. In this case, it was set to gene indicating that the counting is performed at the gene level.

mkdir Quantifications

# Iterate over all *out.bam files in the directory
for file in $directory/*out.bam; do
  # Execute the htseq-count command for each file
  htseq-count -f bam -r pos -s yes -i gene_id -t gene -n 32 \
  "$file" \
  ../GRCh38.gtf  > "Quantifications/raw.counts.orig$(basename "$file" ).txt"
done

directory="Duplicates/Samples"
for file in $directory/*out.dup.bam; do
  # Execute the htseq-count command for each file
  htseq-count -f bam -r pos -s yes -i gene_id -t gene -n 32 \
  "$file" \
  ../GRCh38.gtf  > "Quantifications/raw.counts.dup$(basename "$file" ).txt"
done

# In order to determine if there are specific samples that contribute significantly to the high level of duplicates and to assess if these samples exhibit 
# consistent dynamics among themselves (allowing for comparisons between them), an analysis known as "dupRadar" is performed individually on each sample.
# When DupRadar is performed in R, it is observed that the level of duplicates in samples S7_3, S9_2, S16_2, S18_1, S18_2, and S22_1 is considerably higher 
# compared to the other samples. Due to this reason, the decision is made to exclude them from the study.

mkdir  Problematic_samples
mv S7_3.fastq.gz S9_2.fastq.gz S16_2.fastq.gz S18_1.fastq.gz S18_2.fastq.gz S22_1.fastq.gz Samples_removed_study/


# To assess whether the general percentage of duplications in the samples improves after eliminating these challenging samples, the alignment, marking, and 
# visualization procedure DupRadar is repeated without including these problematic samples.

mkdir Alignments/Samples_without_problematics

STAR --runThreadN 30 \
     --genomeDir Alignments/genomeIndex \
     --readFilesIn S10_1.fastq.gz,S12_2.fastq.gz,S14_2.fastq.gz,S17_1.fastq.gz,S19_3.fastq.gz,S24_1.fastq.gz,S3_3.fastq.gz,S6_2.fastq.gz,S10_2.fastq.gz,S12_3.fastq.gz,S14_3.fastq.gz,S17_2.fastq.gz,S20_1.fastq.gz,S22_2.fastq.gz,S24_2.fastq.gz,S4_1.fastq.gz,S6_3.fastq.gz,S10_3.fastq.gz,S1_2.fastq.gz,S15_1.fastq.gz,S17_3.fastq.gz,S20_2.fastq.gz,S22_3.fastq.gz,S24_3.fastq.gz,S4_2.fastq.gz,S7_1.fastq.gz,S11_1.fastq.gz,S13_1.fastq.gz,S15_2.fastq.gz,S20_3.fastq.gz,S2_2.fastq.gz,S25_1.fastq.gz,S4_3.fastq.gz,S7_2.fastq.gz,S11_2.fastq.gz,S13_2.fastq.gz,S15_3.fastq.gz,S21_1.fastq.gz,S23_1.fastq.gz,S25_2.fastq.gz,S5_1.fastq.gz,S11_3.fastq.gz,S13_3.fastq.gz,S16_1.fastq.gz,S18_3.fastq.gz,S21_2.fastq.gz,S23_2.fastq.gz,S25_3.fastq.gz,S5_2.fastq.gz,S9_1.fastq.gz,S1_1.fastq.gz,S1_3.fastq.gz,S19_1.fastq.gz,S21_3.fastq.gz,S23_3.fastq.gz,S3_1.fastq.gz,S5_3.fastq.gz,S12_1.fastq.gz,S14_1.fastq.gz,S16_3.fastq.gz,S19_2.fastq.gz,S2_1.fastq.gz,S2_3.fastq.gz,S3_2.fastq.gz,S6_1.fastq.gz,S9_3.fastq.gz \
     --outSAMunmapped Within \
     --outSAMattributes NH HI AS NM MD \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix Alignments/Samples_without_problematics

mkdir Duplicates/Samples_without_problematics

sambamba markdup -t 32 -p --tmpdir Duplicates Alignments/Samples_without_problematics/Aligned.sortedByCoord.out.bam  Duplicates/Samples_without_problematics/Aligned.sortedByCoord.out.mark.bam


# Some of the samples have a very high percentage of duplicates (approximately 90% at different levels of gene expression) and/or a very low sequencing depth
# after removing the duplicates. Since our samples were run three times on the sequencer, we want to determine whether the high percentage of duplications is 
# inherent to the sample or originates from any of these runs. In order to do so, our transcripts are aligned to the genome, duplicates are marked using
# Sambamba, and dupRadar is performed to observe the association between gene expression level and the percentage of duplications.

cd ..
sample_files=("S10_1.fastq.gz" "S22_1.fastq.gz" "S1_2.fastq.gz" "S18_1.fastq.gz" "S18_2.fastq.gz" "S7_3.fastq.gz" "S16_2.fastq.gz" "S9_2.fastq.gz")

# 1rst run of the samples 

for file in "${sample_files[@]}"
do
output_prefix="merged_quality/Alignments/problematic_samples/1rst_read/${file%.fastq.gz}"

STAR --runThreadN 32 \
     --genomeDir merged_quality/Alignments/genomeIndex \
     --readFilesIn 1st_read/Problematic_samples/"$file" \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix "$output_prefix"
done

# Set the path to the directory containing the BAM files
directory="1st_read/Problematic_samples/"


# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Extract the filename without the extension
  filename=$(basename "$file" .out.bam)

  # Execute the sambamba markdup command for each file
  sambamba markdup -t 32 -p --tmpdir Duplicates "$file" "Duplicates/Problematic_samples/1rst_read/${filename}.mark.bam"
done

# 2nd run of the samples 

for file in "${sample_files[@]}"
do
output_prefix="merged_quality/Alignments/problematic_samples/2nd_read/${file%.fastq.gz}"

STAR --runThreadN 32 \
     --genomeDir merged_quality/Alignments/genomeIndex \
     --readFilesIn 2nd_read/Problematic_samples/"$file" \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix "$output_prefix"
done

# Set the path to the directory containing the BAM files
directory="2nd_read/Problematic_samples/"

# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Extract the filename without the extension
  filename=$(basename "$file" .out.bam)

  # Execute the sambamba markdup command for each file
  sambamba markdup -t 32 -p --tmpdir Duplicates "$file" "Duplicates/Problematic_samples/2nd_read/${filename}.mark.bam"
done

# 3rd run of the samples 

for file in "${sample_files[@]}"
do
output_prefix="merged_quality/Alignments/problematic_samples/3rd_read/${file%.fastq.gz}"

STAR --runThreadN 32 \
     --genomeDir merged_quality/Alignments/genomeIndex \
     --readFilesIn 3rd_read/Problematic_samples/"$file" \
     --readFilesCommand pigz -p32 -dc \
     --outSAMtype BAM SortedByCoordinate \
     --outFileNamePrefix "$output_prefix"
done

# Set the path to the directory containing the BAM files
directory="3rd_read/Problematic_samples/"

# Iterate over all .out.bam files in the directory
for file in $directory/*.out.bam; do
  # Extract the filename without the extension
  filename=$(basename "$file" .out.bam)

  # Execute the sambamba markdup command for each file
  sambamba markdup -t 32 -p --tmpdir Duplicates "$file" "Duplicates/Problematic_samples/3rd_read/${filename}.mark.bam"
done
